{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.3'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas opiera się na dwóch głównych strukturach:\n",
    "\n",
    "* **Series:** Jednowymiarowa tablica z etykietami. Można ją traktować jako kolumnę w arkuszu kalkulacyjnym.\n",
    "* **DataFrame:** Dwuwymiarowa tablica z etykietami wierszy i kolumn. Przypomina tabelę w bazie danych lub arkusz kalkulacyjny.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# Tworzenie obiektu Series\n",
    "s = pd.Series(data=[3, 2, 4, 6, 5])\n",
    "s_index = pd.Series(\n",
    "    data=[3, 2, 4, 6, 5], index=[\"a\", \"b\", \"c\", \"d\", \"e\"], name=\"sample\"\n",
    ")\n",
    "s\n",
    "s_index\n",
    "\n",
    "# Do elementów Series możemy odwoływać się za pomocą indeksów:\n",
    "print(s_index[\"c\"])  # Wynik: 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uzupełnienie braków w danych\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    3.0\n",
       "b    2.0\n",
       "c    NaN\n",
       "d    6.0\n",
       "e    5.0\n",
       "Name: sample, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(\n",
    "    data=[3, 2, np.nan, 6, 5], index=[\"a\", \"b\", \"c\", \"d\", \"e\"], name=\"sample\"\n",
    ")  # np.nan - pusty obiekt, wartość NaN\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wartoś NaN \n",
    "\n",
    "- `NaN` (Not a Number) to specjalna wartość zmiennoprzecinkowa w NumPy, która reprezentuje niezdefiniowany lub niereprezentowalny wynik. Na przykład, 0/0 lub pierwiastek kwadratowy z liczby ujemnej.\n",
    "\n",
    "- `NaN` jest często używany do reprezentowania brakujących danych w zbiorach danych.\n",
    "\n",
    "### Funkcje do obsługi NaN\n",
    "- `np.nan_to_num(x)`: Zastępuje NaN wartością 0.\n",
    "- `np.nanmean()`: Oblicza średnią, ignorując NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False  True]\n",
      " [False  True False]\n",
      " [ True False False]]\n",
      "[[1. 2. 0.]\n",
      " [4. 0. 6.]\n",
      " [0. 8. 9.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Użyj np.nan\n",
    "x = np.nan\n",
    "\n",
    "# Użyj np.array() z dtype=float\n",
    "y = np.array([1, 2, np.nan], dtype=float)\n",
    "\n",
    "# Użyj np.isnan()\n",
    "np.isnan(x)  # True\n",
    "\n",
    "\n",
    "# Utwórz macierz z NaN\n",
    "macierz = np.array([[1, 2, np.nan], [4, np.nan, 6], [np.nan, 8, 9]])\n",
    "\n",
    "# Sprawdź, które elementy są NaN\n",
    "nan_indeksy = np.isnan(macierz)\n",
    "print(nan_indeksy)\n",
    "# [[False False  True]\n",
    "#  [False  True False]\n",
    "#  [ True False False]]\n",
    "\n",
    "# Zastąp NaN wartością 0\n",
    "macierz_bez_nan = np.nan_to_num(macierz)\n",
    "print(macierz_bez_nan)\n",
    "# [[1. 2. 0.]\n",
    "#  [4. 0. 6.]\n",
    "#  [0. 8. 9.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-10-14    0\n",
       "2024-10-15    1\n",
       "2024-10-16    2\n",
       "2024-10-17    3\n",
       "2024-10-18    4\n",
       "2024-10-19    5\n",
       "2024-10-20    6\n",
       "2024-10-21    7\n",
       "2024-10-22    8\n",
       "2024-10-23    9\n",
       "Freq: D, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tworzenie obiektu Series z Data jako indeks\n",
    "\n",
    "data_indeks = pd.Series(\n",
    "    data=np.arange(10), index=pd.date_range(\"2024-10-14\", periods=10)\n",
    ")\n",
    "\n",
    "data_indeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    python\n",
      "1      java\n",
      "2       sql\n",
      "Name: language, dtype: object\n",
      "Index(['a', 'b', 'c', 'd', 'e'], dtype='object')\n",
      "[3 2 4 6 5]\n"
     ]
    }
   ],
   "source": [
    "# Tworzenie obiektu series zawierającego dane tekstowe\n",
    "\n",
    "s_text = pd.Series(data=[\"python\", \"java\", \"sql\"], name=\"language\")\n",
    "\n",
    "\n",
    "print(s_text)\n",
    "print(s_index.index)\n",
    "print(s_index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "4\n",
      "count      4.000000\n",
      "mean     265.000000\n",
      "std      166.032125\n",
      "min       60.000000\n",
      "25%      165.000000\n",
      "50%      300.000000\n",
      "75%      400.000000\n",
      "max      400.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "price = pd.Series(data={\"apple\": 200, \"CD Projekt\": 60, \"Google\": 400, \"amazon\": 400})\n",
    "price\n",
    "\n",
    "print(price[\"apple\"])\n",
    "# print(price[0])\n",
    "\n",
    "# Zlicz elementy\n",
    "print(price.count())\n",
    "\n",
    "# Zlicza ile razy występuje ta sama wartosc\n",
    "\n",
    "price.value_counts()\n",
    "\n",
    "print(price.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oto najważniejsze atrybuty obiektu `Series` w bibliotece pandas:\n",
    "\n",
    "* **`values`**: Zwraca tablicę NumPy zawierającą wartości `Series`.\n",
    "* **`index`**: Zwraca etykiety indeksu `Series`.\n",
    "* **`dtype`**: Zwraca typ danych elementów `Series`.\n",
    "* **`size`**: Zwraca liczbę elementów `Series`.\n",
    "* **`name`**: Zwraca nazwę `Series` (jeśli jest ustawiona).\n",
    "* **`shape`**: Zwraca kształt `Series` (w tym przypadku zawsze będzie to (n,), gdzie n to liczba elementów).\n",
    "* **`nbytes`**: Zwraca rozmiar `Series` w bajtach.\n",
    "* **`ndim`**: Zwraca liczbę wymiarów `Series` (w tym przypadku zawsze będzie to 1).\n",
    "\n",
    "Te atrybuty dostarczają podstawowych informacji o obiekcie `Series` i są często używane do eksploracji i analizy danych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Najważniejsze metody Data Series\n",
    "\n",
    "Obiekty `Data Series` w bibliotece pandas oferują wiele metod do manipulacji i analizy danych. Oto niektóre z najważniejszych:\n",
    "\n",
    "*   `.head()`: Zwraca pierwsze n wierszy `Series` (domyślnie 5).\n",
    "*   `.tail()`: Zwraca ostatnie n wierszy `Series` (domyślnie 5).\n",
    "*   `.describe()`: Zwraca podstawowe statystyki opisowe `Series`, takie jak średnia, odchylenie standardowe, minimum, maksimum itp.\n",
    "*   `.value_counts()`: Zwraca liczbę wystąpień każdej unikalnej wartości w `Series`.\n",
    "*   `.sort_values()`: Sortuje `Series` według wartości.\n",
    "*   `.sort_index()`: Sortuje `Series` według indeksu.\n",
    "*   `.fillna()`: Wypełnia brakujące wartości w `Series`.\n",
    "*   `.dropna()`: Usuwa brakujące wartości z `Series`.\n",
    "*   `.apply()`: Stosuje funkcję do każdego elementu `Series`.\n",
    "*   `.map()`: Ma zastosowanie do każdego elementu `Series` funkcji lub słownika mapującego.\n",
    "*   `.astype()`: Konwertuje typ danych `Series`.\n",
    "*   `.isin()`: Sprawdza, czy elementy `Series` znajdują się w podanej liście wartości.\n",
    "*   `.between()`: Sprawdza, czy elementy `Series` znajdują się w podanym przedziale.\n",
    "*   `.unique()`: Zwraca unikalne wartości `Series`.\n",
    "*   `.nunique()`: Zwraca liczbę unikalnych wartości `Series`.\n",
    "*   `.idxmax()`: Zwraca indeks elementu o maksymalnej wartości.\n",
    "*   `.idxmin()`: Zwraca indeks elementu o minimalnej wartości.\n",
    "*   `.sum()`: Zwraca sumę elementów `Series`.\n",
    "*   `.mean()`: Zwraca średnią arytmetyczną elementów `Series`.\n",
    "*   `.median()`: Zwraca medianę elementów `Series`.\n",
    "*   `.std()`: Zwraca odchylenie standardowe elementów `Series`.\n",
    "*   `.var()`: Zwraca wariancję elementów `Series`.\n",
    "*   `.quantile()`: Zwraca kwantyl o podanym poziomie.\n",
    "*   `.count()`: Zwraca liczbę niepustych elementów `Series`.\n",
    "*   `.to_csv()`: Zapisuje `Series` do pliku CSV.\n",
    "*   `.to_excel()`: Zapisuje `Series` do pliku Excel.\n",
    "\n",
    "## Przykład\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Utwórz Series\n",
    "s = pd.Series([10, 20, 30, 40, 50], index=['a', 'b', 'c', 'd', 'e'])\n",
    "\n",
    "# Wyświetl pierwsze 3 elementy\n",
    "print(s.head(3))\n",
    "\n",
    "# Wyświetl podstawowe statystyki\n",
    "print(s.describe())\n",
    "\n",
    "# Zastosuj funkcję lambda do każdego elementu\n",
    "print(s.apply(lambda x: x * 2))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W obiekcie DataSeries index może się powtarzać !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Metoda `squeeze()` służy do konwersji DataFrame z jedną kolumną do Series. Jest to bardziej \"pandasowy\" sposób na osiągnięcie tego samego rezultatu. \n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Wczytaj dane z pliku CSV\n",
    "s = pd.read_csv('dane.csv', header=None, index_col=0).squeeze()\n",
    "\n",
    "# Wyświetl Series\n",
    "print(s)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metody i właściwości Data Series do pobierania wartości\n",
    "Pandas Series oferuje różnorodne metody i właściwości, które pozwalają na pobieranie wartości. Oto omówienie niektórych z nich:\n",
    "\n",
    "Metody\n",
    "- iloc[]: Pobieranie wartości za pomocą indeksów liczbowych.\n",
    "- loc[]: Pobieranie wartości za pomocą etykiet.\n",
    "- at[]: Pobieranie pojedynczej wartości za pomocą etykiety.\n",
    "- iat[]: Pobieranie pojedynczej wartości za pomocą indeksu liczbowego.\n",
    "- get(): Pobieranie wartości za pomocą etykiety z domyślną wartością, jeśli etykieta nie istnieje.\n",
    "\n",
    "Właściwości\n",
    "- .values: Pobiera wszystkie wartości serii jako tablicę NumPy.\n",
    "- .index: Pobiera indeksy serii.\n",
    "- .size: Pobiera rozmiar serii.\n",
    "- .empty: Sprawdza, czy seria jest pusta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Różnice między metodami i właściwościami w Data Series\n",
    "\n",
    "### iloc[] vs. loc[]: (preferowane)\n",
    "\n",
    "- iloc[]: Używa liczbowych indeksów pozycyjnych. Używany do dostępu przez pozycję indeksu.\n",
    "- loc[]: Używa etykiet indeksów (kluczy). Używany do dostępu przez nazwane etykiety indeksów.\n",
    "\n",
    "### at[] vs. iat[]:\n",
    "\n",
    "- at[]: Służy do pobierania pojedynczej wartości za pomocą etykiety indeksu. Jest szybszy niż loc[] dla pojedynczych elementów.\n",
    "- iat[]: Służy do pobierania pojedynczej wartości za pomocą liczbowego indeksu pozycyjnego. Jest szybszy niż iloc[] dla pojedynczych elementów.\n",
    "\n",
    "### get():\n",
    "\n",
    "- get(): Pobiera wartość na podstawie etykiety indeksu z opcjonalną wartością domyślną, jeśli etykieta nie istnieje. Przydatny, gdy nie jesteśmy pewni, czy etykieta istnieje.\n",
    "\n",
    "### .values vs. .index vs. .size vs. .empty:\n",
    "\n",
    "- .values: Zwraca wszystkie wartości serii jako tablicę NumPy.\n",
    "- .index: Zwraca indeksy serii.\n",
    "- .size: Zwraca liczbę elementów w serii.\n",
    "- .empty: Sprawdza, czy seria jest pusta i zwraca True lub False.\n",
    "\n",
    "## Najlepsze praktyki\n",
    "Wybór odpowiedniej metody:\n",
    "\n",
    "- Używaj iloc[], gdy znasz pozycję indeksu, a loc[], gdy pracujesz z etykietami.\n",
    "- Używaj at[] i iat[], gdy potrzebujesz szybkiego dostępu do pojedynczej wartości.\n",
    "\n",
    "### Bezpieczne pobieranie wartości:\n",
    "\n",
    "    Używaj get(), gdy nie jesteś pewien, czy dana etykieta istnieje. Dzięki temu unikniesz błędów KeyError.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Przykładowe dane\n",
    "series = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n",
    "\n",
    "# Użycie metody get() z wartością domyślną\n",
    "value = series.get('d', default='Wartość domyślna')\n",
    "\n",
    "print(value)  # Powinno zwrócić 'Wartość domyślna'\n",
    "\n",
    "```\n",
    "\n",
    "- Manipulacja wartościami:\n",
    "\n",
    "    Używaj .values do przekształcania serii na tablicę NumPy, gdy planujesz przeprowadzać operacje numeryczne na dużych zbiorach danych.\n",
    "\n",
    "- Sprawdzanie właściwości serii:\n",
    "\n",
    "    Regularnie korzystaj z .index, .size i .empty, aby zrozumieć strukturę i stan swojej serii.\n",
    "\n",
    "- Unikanie błędów:\n",
    "\n",
    "    Sprawdź, czy indeksy lub etykiety istnieją przed dostępem do wartości, aby uniknąć wyjątków IndexError i KeyError."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przykład użycia loc i reindex w pandas, gdy jeden z szukanych indeksów nie istnieje\n",
    "\n",
    "Gdy próbujesz uzyskać wartości za pomocą loc, a szukany indeks nie istnieje, pandas zgłosi błąd KeyError.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Przykładowe dane\n",
    "data = {'A': [1, 2, 3], 'B': [4, 5, 6]}\n",
    "df = pd.DataFrame(data, index=['x', 'y', 'z'])\n",
    "\n",
    "# Próbuj uzyskać wartości dla istniejących i nieistniejących indeksów za pomocą loc\n",
    "try:\n",
    "    result_loc = df.loc[['x', 'y', 'w']]\n",
    "except KeyError as e:\n",
    "    print(\"KeyError:\", e)\n",
    "\n",
    "```\n",
    "\n",
    "W powyższym przykładzie loc zgłosi KeyError, ponieważ indeks 'w' nie istnieje w DataFrame.\n",
    "\n",
    "- Użycie reindex\n",
    "Gdy używasz reindex i jeden z nowych indeksów nie istnieje w oryginalnym obiekcie, pandas doda ten indeks z wartością NaN.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Przykładowe dane\n",
    "data = {'A': [1, 2, 3], 'B': [4, 5, 6]}\n",
    "df = pd.DataFrame(data, index=['x', 'y', 'z'])\n",
    "\n",
    "# Reindeksowanie z brakującymi indeksami\n",
    "new_index = ['x', 'y', 'w']\n",
    "df_reindexed = df.reindex(new_index)\n",
    "\n",
    "print(df_reindexed)\n",
    "\n",
    "```\n",
    "Wynik:\n",
    "\n",
    "```text\n",
    "     A    B\n",
    "x  1.0  4.0\n",
    "y  2.0  5.0\n",
    "w  NaN  NaN\n",
    "\n",
    "```\n",
    "\n",
    "W powyższym przykładzie reindex dodał nowy indeks 'w' z wartościami NaN, ponieważ ten indeks nie istniał w oryginalnym DataFrame.\n",
    "\n",
    "Podsumowanie\n",
    "`loc`: Podnosi KeyError, gdy próbujesz uzyskać wartości dla nieistniejących indeksów. `reindex`: Dodaje brakujące indeksy z wartościami NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intersection\n",
    "\n",
    "# Wyszuka tylko dane występujące razem w obu zboiorach i pominie te których brak bez wyświetlenia błędu\n",
    "\n",
    "# Idxmin, Idxmax - numery indeksów na których występują minimnalne i maksymalne wartosci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Metoda map\n",
    "\n",
    "Metoda `map` w Pandas Series pozwala na mapowanie wartości z jednej serii na wartości z innej serii. W tym przypadku, seria A dostarcza indeks, a seria B dostarcza wartości. \n",
    "\n",
    "**Przykład:**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Seria A (indeks)\n",
    "seria_a = pd.Series(['jabłko', 'banan', 'gruszka'], index=[1, 2, 3])\n",
    "\n",
    "# Seria B (wartości)\n",
    "seria_b = pd.Series([10, 20, 30], index=['jabłko', 'banan', 'gruszka'])\n",
    "\n",
    "# Połączenie serii A i B za pomocą metody map\n",
    "wynik = seria_a.map(seria_b)\n",
    "\n",
    "# Wyświetlenie wyniku\n",
    "print(wynik)\n",
    "```\n",
    "\n",
    "**Wynik:**\n",
    "\n",
    "```\n",
    "1    10\n",
    "2    20\n",
    "3    30\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "W tym przykładzie, `seria_a` zawiera indeksy (1, 2, 3) i odpowiadające im etykiety ('jabłko', 'banan', 'gruszka'). `seria_b` zawiera etykiety jako indeks i wartości (10, 20, 30). Metoda `map` zastosowana do `seria_a` z argumentem `seria_b` tworzy nową serię, w której indeksem są indeksy z `seria_a`, a wartościami są wartości z `seria_b` odpowiadające etykietom z `seria_a`.\n",
    "\n",
    "Metoda `map` jest bardzo przydatna do łączenia danych z różnych źródeł, gdy mamy wspólną kolumnę lub indeks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame \n",
    "\n",
    "DataFrame to dwuwymiarowa struktura danych,  która przypomina tabelę w bazie danych lub arkusz kalkulacyjny. Składa się z wierszy i kolumn, gdzie każda kolumna może mieć inny typ danych (liczby, tekst, daty itp.). DataFrame posiada etykiety wierszy (indeks) i etykiety kolumn.\n",
    "\n",
    "### Tworzenie DataFrame\n",
    "DataFrame można utworzyć na wiele sposobów, np. z:\n",
    "\n",
    "- słownika list lub tablic\n",
    "- listy słowników\n",
    "- pliku CSV\n",
    "- tabeli bazy danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Imię</th>\n",
       "      <th>Wiek</th>\n",
       "      <th>Miasto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jan</td>\n",
       "      <td>25</td>\n",
       "      <td>Warszawa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anna</td>\n",
       "      <td>30</td>\n",
       "      <td>Kraków</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Piotr</td>\n",
       "      <td>28</td>\n",
       "      <td>Poznań</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Maria</td>\n",
       "      <td>22</td>\n",
       "      <td>Gdańsk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Imię  Wiek    Miasto\n",
       "0    Jan    25  Warszawa\n",
       "1   Anna    30    Kraków\n",
       "2  Piotr    28    Poznań\n",
       "3  Maria    22    Gdańsk"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    "    data={\"Cena\": [10, 20, 30], \"Ilość\": [2, 3, 4]}, index=[\"a\", \"b\", \"c\"]\n",
    ")\n",
    "df\n",
    "\n",
    "# Utwórz DataFrame ze słownika list\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Imię\": [\"Jan\", \"Anna\", \"Piotr\", \"Maria\"],\n",
    "        \"Wiek\": [25, 30, 28, 22],\n",
    "        \"Miasto\": [\"Warszawa\", \"Kraków\", \"Poznań\", \"Gdańsk\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dostęp do Danych\n",
    "\n",
    "Do danych w DataFrame można odwoływać się na wiele sposobów:\n",
    "\n",
    "*   za pomocą etykiet kolumn (`df['Imię']`)\n",
    "*   za pomocą atrybutów (`df.Imię`)\n",
    "*   za pomocą indeksowania (`df.iloc[0, 1]`)\n",
    "*   za pomocą indeksowania logicznego (`df[df['Wiek'] > 25]`)\n",
    "\n",
    "### Atrybuty i Metody\n",
    "\n",
    "DataFrame posiada wiele atrybutów i metod, które ułatwiają pracę z danymi:\n",
    "\n",
    "*   `shape`: Zwraca wymiary DataFrame (liczba wierszy, liczba kolumn).\n",
    "*   `columns`: Zwraca etykiety kolumn.\n",
    "*   `index`: Zwraca etykiety wierszy.\n",
    "*   `head()`: Wyświetla pierwsze n wierszy.\n",
    "*   `tail()`: Wyświetla ostatnie n wierszy.\n",
    "*   `describe()`: Wyświetla podstawowe statystyki opisowe.\n",
    "*   `info()`: Wyświetla informacje o DataFrame (typy danych, brakujące wartości).\n",
    "*   `sort_values()`: Sortuje DataFrame według wartości w kolumnie.\n",
    "*   `groupby()`: Grupuje dane według wartości w kolumnie.\n",
    "\n",
    "### Ściąga na Egzamin\n",
    "\n",
    "*   **DataFrame:** Dwuwymiarowa tabela z etykietami wierszy i kolumn.\n",
    "*   **Tworzenie:** `pd.DataFrame(dane)`\n",
    "*   **Dostęp do danych:** `df['kolumna']`, `df.kolumna`, `df.iloc[]`, `df.loc[]`\n",
    "*   **Atrybuty:** `shape`, `columns`, `index`\n",
    "*   **Metody:** `head()`, `tail()`, `describe()`, `info()`, `sort_values()`, `groupby()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Zadania\n",
    "\n",
    "# 1. Utwórz DataFrame z danymi o studentach (imię, nazwisko, wiek, kierunek).\n",
    "# 2. Wyświetl tylko dane studentów, którzy mają więcej niż 22 lata.\n",
    "# 3. Posortuj DataFrame według wieku studentów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Odpowiedzi do Zadań\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Zadanie 1\n",
    "dane_studentow = {\n",
    "    \"Imię\": [\"Jan\", \"Anna\", \"Piotr\", \"Maria\"],\n",
    "    \"Nazwisko\": [\"Kowalski\", \"Nowak\", \"Wiśniewski\", \"Kamińska\"],\n",
    "    \"Wiek\": [25, 30, 28, 22],\n",
    "    \"Kierunek\": [\"Informatyka\", \"Matematyka\", \"Fizyka\", \"Biologia\"],\n",
    "}\n",
    "df_studenci = pd.DataFrame(dane_studentow)\n",
    "\n",
    "# Zadanie 2\n",
    "starsi_studenci = df_studenci[df_studenci[\"Wiek\"] > 22]\n",
    "print(\"Starsi studenci:\\n\", starsi_studenci, \"\\n\")\n",
    "\n",
    "# Zadanie 3\n",
    "posortowani_studenci = df_studenci.sort_values(\"Wiek\")\n",
    "print(\"Posortowani studenci:\\n\", posortowani_studenci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funkcja apply()\n",
    "\n",
    "Funkcja `apply()` w bibliotece pandas służy do stosowania funkcji do każdego wiersza lub kolumny DataFrame'u. Jest to bardzo elastyczne narzędzie, które pozwala na wykonywanie różnego rodzaju operacji na danych.\n",
    "\n",
    "### Składnia\n",
    "\n",
    "```python\n",
    "df.apply(func, axis=0, raw=False, result_type=None, args=(), **kwargs)\n",
    "```\n",
    "\n",
    "* `func`: Funkcja do zastosowania.\n",
    "* `axis`: Oś, wzdłuż której ma być zastosowana funkcja (0 dla kolumn, 1 dla wierszy).\n",
    "* `raw`: Jeśli True, przekazuje funkcjom tablice NumPy zamiast obiektów Series.\n",
    "* `result_type`: Określa typ zwracanego obiektu ('expand', 'reduce', 'broadcast').\n",
    "* `args`: Dodatkowe argumenty pozycyjne dla funkcji.\n",
    "* `kwargs`: Dodatkowe argumenty nazwane dla funkcji.\n",
    "\n",
    "### Przykłady\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Utwórz DataFrame\n",
    "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9]})\n",
    "\n",
    "# Zastosuj funkcję lambda do każdej kolumny\n",
    "df_apply_kolumny = df.apply(lambda x: x * 2, axis=0)\n",
    "print(df_apply_kolumny)\n",
    "#     A   B   C\n",
    "# 0  2   8  14\n",
    "# 1  4  10  16\n",
    "# 2  6  12  18\n",
    "\n",
    "# Zastosuj funkcję lambda do każdego wiersza\n",
    "df_apply_wiersze = df.apply(lambda x: x * 2, axis=1)\n",
    "print(df_apply_wiersze)\n",
    "#     A   B   C\n",
    "# 0  2   8  14\n",
    "# 1  4  10  16\n",
    "# 2  6  12  18\n",
    "\n",
    "# Zastosuj funkcję zdefiniowaną przez użytkownika do każdej kolumny\n",
    "def dodaj_10(x):\n",
    "  return x + 10\n",
    "\n",
    "df_apply_dodaj_10 = df.apply(dodaj_10, axis=0)\n",
    "print(df_apply_dodaj_10)\n",
    "#     A   B   C\n",
    "# 0  11  14  17\n",
    "# 1  12  15  18\n",
    "# 2  13  16  19\n",
    "```\n",
    "\n",
    "### Ściąga\n",
    "\n",
    "* `apply()` stosuje funkcję do wierszy lub kolumn DataFrame'u.\n",
    "* `axis=0`: kolumny, `axis=1`: wiersze.\n",
    "* Można używać funkcji lambda i funkcji zdefiniowanych przez użytkownika.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Zadania\n",
    "\n",
    "# 1. Utwórz DataFrame z kolumnami 'Cena' i 'Ilość'.\n",
    "# 2. Użyj `apply()` do obliczenia wartości kolumny 'Wartość' jako iloczyn 'Cena' * 'Ilość'.\n",
    "# 3. **(Zadanie trudniejsze)** Napisz funkcję, która normalizuje wartości w kolumnie do przedziału 0-1 i zastosuj ją do DataFrame'u."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Odpowiedzi do Zadań\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Zadanie 1\n",
    "df = pd.DataFrame({\"Cena\": [10, 20, 30], \"Ilość\": [2, 3, 4]})\n",
    "\n",
    "# Zadanie 2\n",
    "df[\"Wartość\"] = df.apply(lambda row: row[\"Cena\"] * row[\"Ilość\"], axis=1)\n",
    "print(df, \"\\n\")\n",
    "\n",
    "\n",
    "# Zadanie 3 (trudniejsze)\n",
    "def normalizuj(x):\n",
    "    \"\"\"Normalizuje wartości w Series do przedziału 0-1.\"\"\"\n",
    "    min_val = x.min()\n",
    "    max_val = x.max()\n",
    "    return (x - min_val) / (max_val - min_val)\n",
    "\n",
    "\n",
    "df_norm = df.apply(normalizuj, axis=0)\n",
    "print(df_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dostęp do danych\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Utwórz DataFrame\n",
    "df = pd.DataFrame({'Imię': ['Jan', 'Anna', 'Piotr', 'Maria'],\n",
    "                   'Wiek': [25, 30, 28, 22],\n",
    "                   'Miasto': ['Warszawa', 'Kraków', 'Poznań', 'Gdańsk']})\n",
    "\n",
    "# Wyświetl DataFrame\n",
    "print(\"DataFrame:\\n\", df, \"\\n\")\n",
    "\n",
    "# Wybierz kolumnę \"Wiek\"\n",
    "kolumna_wiek = df[\"Wiek\"]\n",
    "\n",
    "# Wybierz pierwszy wiersz\n",
    "wiersz_0 = df.iloc[0]\n",
    "\n",
    "# Wybierz element z drugiego wiersza i trzeciej kolumny\n",
    "element_1_2 = df.iloc[1, 2]\n",
    "\n",
    "# Wybierz wszystkie wiersze, w których wiek jest większy niż 25\n",
    "df_wiek_25 = df[df['Wiek'] > 25]\n",
    "\n",
    "# Wybierz kolumny 'Imię' i 'Miasto' dla pierwszych dwóch wierszy\n",
    "df_imie_miasto = df.loc[:1, ['Imię', 'Miasto']]\n",
    "\n",
    "# Wyświetl wyniki\n",
    "print(\"Kolumna 'Wiek':\\n\", kolumna_wiek, \"\\n\")\n",
    "print(\"Pierwszy wiersz:\\n\", wiersz_0, \"\\n\")\n",
    "print(\"Element z drugiego wiersza i trzeciej kolumny:\", element_1_2, \"\\n\")\n",
    "print(\"Wiersze, w których wiek jest większy niż 25:\\n\", df_wiek_25, \"\\n\")\n",
    "print(\"Kolumny 'Imię' i 'Miasto' dla pierwszych dwóch wierszy:\\n\", df_imie_miasto, \"\\n\")\n",
    "\n",
    "# Wyświetl typy\n",
    "print(\"Typ kolumna_wiek:\", type(kolumna_wiek))\n",
    "print(\"Typ wiersz_0:\", type(wiersz_0))\n",
    "print(\"Typ element_1_2:\", type(element_1_2))\n",
    "print(\"Typ df_wiek_25:\", type(df_wiek_25))\n",
    "print(\"Typ df_imie_miasto:\", type(df_imie_miasto))\n",
    "```\n",
    "\n",
    "```text\n",
    "\n",
    "DataFrame:\n",
    "     Imię  Wiek    Miasto\n",
    "0    Jan    25  Warszawa\n",
    "1   Anna    30    Kraków\n",
    "2  Piotr    28    Poznań\n",
    "3  Maria    22    Gdańsk \n",
    "\n",
    "Kolumna 'Wiek':\n",
    " 0    25\n",
    "1    30\n",
    "2    28\n",
    "3    22\n",
    "Name: Wiek, dtype: int64 \n",
    "\n",
    "Pierwszy wiersz:\n",
    "Imię           Jan\n",
    "Wiek            25\n",
    "Miasto    Warszawa\n",
    "Name: 0, dtype: object \n",
    "\n",
    "Element z drugiego wiersza i trzeciej kolumny: Kraków \n",
    "\n",
    "Wiersze, w których wiek jest większy niż 25:\n",
    "     Imię  Wiek  Miasto\n",
    "1   Anna    30  Kraków\n",
    "2  Piotr    28  Poznań \n",
    "\n",
    "Kolumny 'Imię' i 'Miasto' dla pierwszych dwóch wierszy:\n",
    "    Imię    Miasto\n",
    "0   Jan  Warszawa\n",
    "1  Anna    Kraków \n",
    "\n",
    "Typ kolumna_wiek: <class 'pandas.core.series.Series'>\n",
    "Typ wiersz_0: <class 'pandas.core.series.Series'>\n",
    "Typ element_1_2: <class 'str'>\n",
    "Typ df_wiek_25: <class 'pandas.core.frame.DataFrame'>\n",
    "Typ df_imie_miasto: <class 'pandas.core.frame.DataFrame'>\n",
    "\n",
    "```\n",
    "\n",
    "W DataFrame można uzyskać dostęp do danych i wycinać ich fragmenty na wiele sposobów:\n",
    "\n",
    "**Wybieranie kolumn:**\n",
    "\n",
    "*   Za pomocą nazwy kolumny: `df['nazwa_kolumny']`\n",
    "*   Za pomocą atrybutu: `df.nazwa_kolumny` (jeśli nazwa kolumny jest prawidłowym identyfikatorem Pythona)\n",
    "\n",
    "**Wybieranie wierszy:**\n",
    "\n",
    "*   Za pomocą `iloc`: `df.iloc[indeks_wiersza]` - wybiera wiersz o podanym indeksie liczbowym\n",
    "*   Za pomocą `loc`: `df.loc[etykieta_wiersza]` - wybiera wiersz o podanej etykiecie\n",
    "\n",
    "**Wybieranie pojedynczych elementów:**\n",
    "\n",
    "*   Za pomocą `iloc`: `df.iloc[indeks_wiersza, indeks_kolumny]`\n",
    "\n",
    "**Wybieranie fragmentów DataFrame:**\n",
    "\n",
    "*   Za pomocą indeksowania logicznego: `df[warunek]` - wybiera wiersze spełniające warunek\n",
    "*   Za pomocą `loc`: `df.loc[etykiety_wierszy, etykiety_kolumn]` - wybiera wiersze i kolumny o podanych etykietach\n",
    "*   Za pomocą `iloc`: `df.iloc[indeksy_wierszy, indeksy_kolumn]` - wybiera wiersze i kolumny o podanych indeksach liczbowych\n",
    "\n",
    "**Typy zwracanych obiektów:**\n",
    "\n",
    "*   Wybieranie pojedynczej kolumny zwraca obiekt `Series`.\n",
    "*   Wybieranie pojedynczego wiersza zwraca obiekt `Series`.\n",
    "*   Wybieranie pojedynczego elementu zwraca wartość elementu (np. liczbę, ciąg znaków).\n",
    "*   Wybieranie fragmentu DataFrame zwraca obiekt `DataFrame`.\n",
    "\n",
    "Pamiętaj, że indeksowanie w Pythonie zaczyna się od 0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metoda dropna() w pandas\n",
    "\n",
    "Metoda dropna() w pandas jest używana do usuwania wierszy lub kolumn, które zawierają wartości NaN. Jest to bardzo przydatne, gdy masz dane z brakującymi wartościami i chcesz pracować tylko z kompletnymi wierszami lub kolumnami.\n",
    "\n",
    "```python\n",
    "DataFrame.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
    "```\n",
    "\n",
    "- Parametry:\n",
    "    - axis: Oznacza, wzdłuż której osi operacja będzie wykonywana. 0 lub 'index' dla wierszy, 1 lub 'columns' dla kolumn.\n",
    "    - how: Oznacza kryterium usuwania. 'any' (domyślne) usuwa wiersz/kolumnę, jeśli jakakolwiek wartość jest NaN. 'all' usuwa wiersz/kolumnę, jeśli wszystkie wartości są NaN.\n",
    "    - thresh: Minimalna liczba brakujących wartości, aby wiersz/kolumna zostały zachowane. Na przykład, thresh=2 oznacza, że wiersz/kolumna muszą mieć co najmniej 2 wartości niebędące NaN, aby zostały zachowane.\n",
    "    - subset: Lista etykiet ograniczająca sprawdzanie NaN do określonych kolumn lub wierszy.\n",
    "    - inplace: Jeśli True, modyfikacje są wprowadzane bezpośrednio do oryginalnego DataFrame. Jeśli False (domyślnie), zwraca zmodyfikowany DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Usuwanie wierszy z jakąkolwiek wartością NaN:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Przykładowe dane\n",
    "data = {\"A\": [1, 2, None], \"B\": [4, None, 6], \"C\": [7, 8, 9]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Usunięcie wierszy z jakąkolwiek wartością NaN\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "print(df_cleaned)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Usuwanie kolumn z jakąkolwiek wartością NaN:\n",
    "\n",
    "```python\n",
    "# Usunięcie kolumn z jakąkolwiek wartością NaN\n",
    "df_cleaned = df.dropna(axis=1)\n",
    "\n",
    "print(df_cleaned)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Usuwanie wierszy, jeśli wszystkie wartości są NaN:\n",
    "\n",
    "```python\n",
    "# Przykładowe dane z wierszem pełnym NaN\n",
    "data = {'A': [None, 2, None], 'B': [None, None, None], 'C': [None, 8, 9]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Usunięcie wierszy, jeśli wszystkie wartości są NaN\n",
    "df_cleaned = df.dropna(how='all')\n",
    "\n",
    "print(df_cleaned)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podsumowanie:\n",
    "Metoda dropna() jest wszechstronnym narzędziem do czyszczenia danych w pandas. Umożliwia usuwanie wierszy lub kolumn zawierających brakujące wartości (NaN) według różnych kryteriów, co pozwala na lepszą organizację i analizę danych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metoda fillna()\n",
    "\n",
    "Metoda fillna() w pandas pozwala na zastępowanie wartości NaN innymi wartościami, a za pomocą słownika możesz określić różne wartości zastępcze dla różnych kolumn. Jest to bardzo elastyczne rozwiązanie, które ułatwia czyszczenie danych w DataFrame, gdzie każda kolumna może wymagać innego podejścia.\n",
    "\n",
    "### Zmiana pojedynczej kolumny\n",
    "\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Przykładowe dane\n",
    "data = {\n",
    "    'Name': ['John', 'Anna', 'Peter', 'Linda'],\n",
    "    'Salary': [50000, None, 55000, None],\n",
    "    'Age': [30, 25, 32, 28]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Oryginalny DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Zastąpienie NaN w kolumnie 'Salary' wartością 0\n",
    "df['Salary'] = df['Salary'].fillna(0)\n",
    "\n",
    "print(\"\\nDataFrame po zastąpieniu NaN w kolumnie 'Salary':\")\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "### Zmiany w wielu kolumnach\n",
    "\n",
    "\n",
    "1. Przykład zastosowania fillna() z użyciem słownika:\n",
    "Importowanie bibliotek i tworzenie przykładowych danych:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Przykładowe dane\n",
    "data = {\n",
    "    'A': [1, None, 3, None],\n",
    "    'B': [None, 2, None, 4],\n",
    "    'C': [5, None, 7, None]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Oryginalny DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "2. Zastosowanie fillna() z użyciem słownika:\n",
    "\n",
    "\n",
    "```python\n",
    "# Słownik z wartościami zastępczymi dla każdej kolumny\n",
    "values_to_fill = {\n",
    "    'A': 0,    # Zastępujemy NaN w kolumnie 'A' zerem\n",
    "    'B': 1,    # Zastępujemy NaN w kolumnie 'B' jedynką\n",
    "    'C': 99    # Zastępujemy NaN w kolumnie 'C' wartością 99\n",
    "}\n",
    "\n",
    "# Wypełnianie NaN wartościami ze słownika\n",
    "df_filled = df.fillna(values_to_fill)\n",
    "\n",
    "print(\"\\nDataFrame po zastąpieniu NaN wartościami ze słownika:\")\n",
    "print(df_filled)\n",
    "\n",
    "```\n",
    "\n",
    "```text\n",
    "Oryginalny DataFrame:\n",
    "     A    B    C\n",
    "0  1.0  NaN  5.0\n",
    "1  NaN  2.0  NaN\n",
    "2  3.0  NaN  7.0\n",
    "3  NaN  4.0  NaN\n",
    "\n",
    "DataFrame po zastąpieniu NaN wartościami ze słownika:\n",
    "     A    B   C\n",
    "0  1.0  1.0   5\n",
    "1  0.0  2.0  99\n",
    "2  3.0  1.0   7\n",
    "3  0.0  4.0  99\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sortowanie danych\n",
    "\n",
    "Sortowanie danych w pandas DataFrame jest łatwe i bardzo przydatne do analizy. Możesz sortować dane według jednej lub wielu kolumn, zarówno rosnąco, jak i malejąco. Metoda sort_values() jest kluczowa do tego celu.\n",
    "\n",
    "\n",
    "### Jak działa sort_values():\n",
    "\n",
    "```python\n",
    "DataFrame.sort_values(by, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last', ignore_index=False, key=None)\n",
    "```\n",
    "\n",
    "Parametry:\n",
    "\n",
    "- by: Kolumna lub lista kolumn, według których chcesz sortować dane. Jest to jedyny wymagany parametr.\n",
    "- axis: Oś, wzdłuż której sortowanie ma być wykonane. 0 (domyślnie) oznacza sortowanie wzdłuż osi wierszy, 1 oznacza sortowanie wzdłuż osi kolumn.\n",
    "- ascending: Określa, czy sortowanie ma być rosnące (True, domyślnie) czy malejące (False). Można podać jedną wartość boolowską lub listę wartości, jeśli sortujemy według wielu kolumn.\n",
    "- inplace: Jeśli True, sortowanie jest wykonywane na miejscu i modyfikuje oryginalny DataFrame. Jeśli False (domyślnie), zwraca nowy posortowany DataFrame.\n",
    "- kind: Rodzaj algorytmu sortowania. Do wyboru: 'quicksort', 'mergesort', 'heapsort', 'stable'. Domyślnie 'quicksort'.\n",
    "- na_position: Określa, gdzie wartości NaN mają być umieszczone. 'first' umieszcza je na początku, 'last' (domyślnie) na końcu.\n",
    "- ignore_index: Jeśli True, nowe indeksy są przypisane do sortowanego DataFrame lub Series, ignorując oryginalne indeksy. Domyślnie False.\n",
    "- key: Funkcja, która jest stosowana do wartości przed sortowaniem. Jest nowością od wersji pandas 1.1.0.\n",
    "\n",
    "\n",
    "Przykład sortowania według jednej kolumny:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Przykładowe dane\n",
    "data = {\n",
    "    'Name': ['John', 'Anna', 'Peter', 'Linda'],\n",
    "    'Salary': [50000, 60000, 55000, 58000],\n",
    "    'Age': [30, 25, 32, 28]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Oryginalny DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Sortowanie według kolumny 'Salary'\n",
    "df_sorted = df.sort_values(by='Salary')\n",
    "\n",
    "print(\"\\nDataFrame posortowany według kolumny 'Salary':\")\n",
    "print(df_sorted)\n",
    "\n",
    "```\n",
    "\n",
    "Przykład sortowania według wielu kolumn:\n",
    "\n",
    "```python\n",
    "# Sortowanie według kolumn 'Age' i 'Salary'\n",
    "df_sorted_multi = df.sort_values(by=['Age', 'Salary'])\n",
    "\n",
    "print(\"\\nDataFrame posortowany według kolumn 'Age' i 'Salary':\")\n",
    "print(df_sorted_multi)\n",
    "```\n",
    "\n",
    "\n",
    "Sortowanie malejące:\n",
    "```python\n",
    "# Sortowanie według kolumny 'Salary' malejąco\n",
    "df_sorted_desc = df.sort_values(by='Salary', ascending=False)\n",
    "\n",
    "print(\"\\nDataFrame posortowany malejąco według kolumny 'Salary':\")\n",
    "print(df_sorted_desc)\n",
    "```\n",
    "\n",
    "Sortowanie z wartościami NaN:\n",
    "\n",
    "```python\n",
    "# Przykładowe dane z wartościami NaN\n",
    "data_with_nan = {\n",
    "    'Name': ['John', 'Anna', 'Peter', 'Linda'],\n",
    "    'Salary': [50000, None, 55000, 58000],\n",
    "    'Age': [30, 25, 32, None]\n",
    "}\n",
    "df_nan = pd.DataFrame(data_with_nan)\n",
    "\n",
    "# Sortowanie z wartościami NaN na początku\n",
    "df_sorted_nan = df_nan.sort_values(by='Salary', na_position='first')\n",
    "\n",
    "print(\"\\nDataFrame posortowany z NaN na początku:\")\n",
    "print(df_sorted_nan)\n",
    "```\n",
    "\n",
    "### Sortowanie po indeksie\n",
    "\n",
    "```python\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Przykładowe dane\n",
    "data = {\n",
    "    'Name': ['John', 'Anna', 'Peter', 'Linda'],\n",
    "    'Salary': [50000, 60000, 55000, 58000],\n",
    "    'Age': [30, 25, 32, 28]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Ustawianie indeksu na kolumnę 'Name'\n",
    "df.set_index('Name', inplace=True)\n",
    "\n",
    "print(\"Oryginalny DataFrame z ustawionym indeksem:\")\n",
    "print(df)\n",
    "\n",
    "# Sortowanie DataFrame według indeksu rosnąco\n",
    "df_sorted_index = df.sort_index()\n",
    "\n",
    "print(\"\\nDataFrame posortowany według indeksu rosnąco:\")\n",
    "print(df_sorted_index)\n",
    "\n",
    "# Sortowanie DataFrame według indeksu malejąco\n",
    "df_sorted_index_desc = df.sort_index(ascending=False)\n",
    "\n",
    "print(\"\\nDataFrame posortowany według indeksu malejąco:\")\n",
    "print(df_sorted_index_desc)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kontrola typów\n",
    "\n",
    "Kontrola typów w pandas jest kluczowym elementem pracy z danymi, umożliwiającym lepszą organizację, przetwarzanie i analizę danych. Pandas dostarcza różne funkcje, które pomagają zarządzać typami danych w DataFrame i Series.\n",
    "\n",
    "### Sprawdzenie typów danych:\n",
    "Możesz sprawdzić typy danych w kolumnach DataFrame za pomocą dtypes.\n",
    "\n",
    "Przykład:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Przykładowe dane\n",
    "data = {'Name': ['John', 'Anna', 'Peter'], 'Age': [30, 25, 32], 'Salary': [50000, 60000, 55000]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Sprawdzenie typów danych\n",
    "print(df.dtypes)\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "### Konwersja typów danych:\n",
    "Możesz konwertować typy danych w DataFrame za pomocą metody astype().\n",
    "\n",
    "Przykład:\n",
    "\n",
    "```python\n",
    "# Konwersja kolumny 'Salary' na typ float\n",
    "df['Salary'] = df['Salary'].astype(float)\n",
    "\n",
    "print(df.dtypes)\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "### Automatyczne konwertowanie typów danych przy wczytywaniu danych:\n",
    "Podczas wczytywania pliku CSV można kontrolować typy danych używając parametru dtype.\n",
    "\n",
    "Przykład:\n",
    "\n",
    "```python\n",
    "df = pd.read_csv('example.csv', dtype={'Age': 'int32', 'Salary': 'float'})\n",
    "print(df.dtypes)\n",
    "\n",
    "```\n",
    "\n",
    "### Obsługa brakujących wartości:\n",
    "Brakujące wartości (NaN) są traktowane jako float w pandas, co czasami wymaga konwersji typów danych, aby dopasować resztę kolumn.\n",
    "\n",
    "Przykład:\n",
    "\n",
    "```python\n",
    "# Przykładowe dane z NaN\n",
    "data = {'Name': ['John', 'Anna', 'Peter'], 'Age': [30, None, 32], 'Salary': [50000, 60000, None]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Konwersja kolumny 'Age' na typ float\n",
    "df['Age'] = df['Age'].astype(float)\n",
    "print(df.dtypes)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optymalizacja typów danych\n",
    "\n",
    "Optymalizacja rozmiaru typów danych jest kluczowym elementem zarządzania pamięcią i wydajnością w pandas. Dobre dopasowanie typów danych pozwala zminimalizować zużycie pamięci i przyspieszyć operacje na DataFrame.\n",
    "\n",
    "Przykłady typowych optymalizacji:\n",
    "- Konwersja typów całkowitych: Zamiast domyślnego typu int64, można użyć mniejszych typów, takich jak int8, int16 lub int32, jeśli wartości w kolumnie są w odpowiednich zakresach.\n",
    "- Konwersja typów zmiennoprzecinkowych: Podobnie, zamiast float64, można użyć float32, jeśli precyzja jest wystarczająca.\n",
    "- Konwersja typu obiektowego na kategorie: Typ object jest stosowany dla tekstu i innych obiektów, co może być bardzo pamięciochłonne. Można zamienić takie kolumny na typ category, co znacznie zmniejsza zużycie pamięci, gdy kolumny zawierają wiele powtarzających się wartości.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Przykładowe dane\n",
    "data = {\n",
    "    'int_column': [1, 2, 3, 4, 5],\n",
    "    'float_column': [1.1, 2.2, 3.3, 4.4, 5.5],\n",
    "    'object_column': ['A', 'B', 'C', 'A', 'B']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Oryginalny DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nOryginalne typy danych:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Optymalizacja typów danych\n",
    "df['int_column'] = df['int_column'].astype(np.int8)\n",
    "df['float_column'] = df['float_column'].astype(np.float32)\n",
    "df['object_column'] = df['object_column'].astype('category')\n",
    "\n",
    "print(\"\\nDataFrame po optymalizacji typów danych:\")\n",
    "print(df)\n",
    "print(\"\\nTypy danych po optymalizacji:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "### Optymalizacja typów na etapie pobierania danych\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Wczytywanie pliku CSV z określeniem typów danych\n",
    "df = pd.read_csv('example.csv', dtype={'Name': 'category', 'Age': 'int8', 'Salary': 'int32'})\n",
    "\n",
    "print(\"Wczytane dane:\")\n",
    "print(df)\n",
    "print(\"\\nTypy danych po optymalizacji:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "```### Optymalizacja typów na etapie pobierania danych\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Wczytywanie pliku CSV z określeniem typów danych\n",
    "df = pd.read_csv('example.csv', dtype={'Name': 'category', 'Age': 'int8', 'Salary': 'int32'})\n",
    "\n",
    "print(\"Wczytane dane:\")\n",
    "print(df)\n",
    "print(\"\\nTypy danych po optymalizacji:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## funkcja rank()\n",
    "\n",
    "Funkcja rank() w pandas jest używana do przypisywania rang do elementów w Series lub DataFrame. Rangi są przypisane w oparciu o wartości elementów i mogą uwzględniać związki (wartości identyczne). Oto kilka najważniejszych aspektów funkcji rank() oraz przykłady, jak z niej korzystać:\n",
    "\n",
    "```python\n",
    "DataFrame.rank(axis=0, method='average', numeric_only=None, na_option='keep', ascending=True, pct=False)\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "### Parametry:\n",
    "\n",
    "- axis: Oś, wzdłuż której będą przypisywane rangi (0 dla wierszy, 1 dla kolumn).\n",
    "- method: Sposób przypisywania rang dla związków:\n",
    "    - 'average' (domyślnie): Przypisuje średnią rangę dla związanych elementów.\n",
    "    - 'min': Przypisuje najniższą rangę dla związanych elementów.\n",
    "    - 'max': Przypisuje najwyższą rangę dla związanych elementów.\n",
    "    - 'first': Przypisuje rangi w kolejności pojawienia się.\n",
    "    - 'dense': Przypisuje rangi tak, że wszystkie elementy mają różne rangi, a związane elementy otrzymują tę samą rangę.\n",
    "- numeric_only: Określa, czy tylko kolumny liczbowe mają być brane pod uwagę.\n",
    "- na_option: Określa sposób traktowania wartości NaN:\n",
    "- 'keep' (domyślnie): Zachowuje wartości NaN.\n",
    "- 'top': Traktuje NaN jako najwy\n",
    "- ascending: Określa, czy elementy powinny być uszeregowane w kolejności rosnącej.\n",
    "- pct: Określa, czy zwrócone rankingi mają być wyświetlane w postaci percentyli."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrowanie danych\n",
    "\n",
    "### Maski logiczne\n",
    "\n",
    "\n",
    "Maska logiczna to obiekt (w Pandas to `Series`) z wartościami `True` lub `False`, który wskazuje, czy dany wiersz spełnia określony warunek. Możemy stosować maski logiczne do filtrowania danych w DataFrame, aby wybrać tylko te wiersze, które mają wartość `True` w masce.\n",
    "\n",
    "- Przykład\n",
    "\n",
    "Załóżmy, że mamy DataFrame z danymi o zamówieniach:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'order_id': [1, 2, 3, 4, 5],\n",
    "    'customer': ['Anna', 'Bartek', 'Celina', 'Daniel', 'Ewa'],\n",
    "    'amount': [150, 240, 50, 330, 90],\n",
    "    'order_date': ['2023-10-05', '2023-10-15', '2023-11-01', '2023-11-05', '2023-11-10']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df['order_date'] = pd.to_datetime(df['order_date'])  # Konwersja na format daty\n",
    "```\n",
    "\n",
    "Chcemy wyfiltrować zamówienia, których `amount` jest większy niż 100. Możemy utworzyć maskę logiczną:\n",
    "\n",
    "```python\n",
    "mask = df['amount'] > 100\n",
    "print(mask)\n",
    "```\n",
    "\n",
    "### Wynik maski:\n",
    "\n",
    "```plaintext\n",
    "0     True\n",
    "1     True\n",
    "2    False\n",
    "3     True\n",
    "4    False\n",
    "Name: amount, dtype: bool\n",
    "```\n",
    "\n",
    "Każdy `True` oznacza, że dany wiersz spełnia warunek (`amount > 100`), a `False` oznacza, że nie spełnia. Możemy teraz użyć tej maski, aby przefiltrować dane:\n",
    "\n",
    "```python\n",
    "filtered_df = df[mask]\n",
    "print(filtered_df)\n",
    "```\n",
    "\n",
    "### Wynik filtrowanego DataFrame:\n",
    "\n",
    "| order_id | customer | amount | order_date |\n",
    "|----------|----------|--------|------------|\n",
    "| 1        | Anna     | 150    | 2023-10-05 |\n",
    "| 2        | Bartek   | 240    | 2023-10-15 |\n",
    "| 4        | Daniel   | 330    | 2023-11-05 |\n",
    "\n",
    "### Dlaczego maski logiczne są przydatne?\n",
    "\n",
    "Maski logiczne pozwalają na oddzielenie warunku od właściwego filtrowania. Dzięki temu:\n",
    "\n",
    "- **Kod jest bardziej czytelny**, ponieważ warunek jest zapisany oddzielnie.\n",
    "- **Można łatwo sprawdzić maskę** (np. wyświetlając ją), aby zobaczyć, które wiersze spełniają dany warunek.\n",
    "- Maski są wielokrotnego użytku — można je zastosować w wielu miejscach, co oszczędza czas i minimalizuje ryzyko błędów.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Filtrowanie danych przykłady\n",
    "\n",
    "Filtracja danych w Pandas to podstawa analizy danych, pozwala skupić się na tych elementach, które nas interesują, i odrzucić resztę. Wyobraź sobie, że masz arkusz kalkulacyjny z informacjami o wszystkich zamówieniach w sklepie, ale chcesz zobaczyć tylko zamówienia z ostatniego miesiąca albo tylko te, których wartość przekracza określoną kwotę. W Pandas wykonujemy to szybko i elastycznie za pomocą filtrowania w DataFrame.\n",
    "\n",
    "## Krok 1: Wczytajmy przykładowe dane\n",
    "\n",
    "Załóżmy, że mamy tabelę zamówień w sklepie internetowym:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Tworzenie przykładowych danych\n",
    "data = {\n",
    "    'order_id': [1, 2, 3, 4, 5],\n",
    "    'customer': ['Anna', 'Bartek', 'Celina', 'Daniel', 'Ewa'],\n",
    "    'amount': [150, 240, 50, 330, 90],\n",
    "    'order_date': ['2023-10-05', '2023-10-15', '2023-11-01', '2023-11-05', '2023-11-10']\n",
    "}\n",
    "\n",
    "# Tworzenie DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df['order_date'] = pd.to_datetime(df['order_date'])  # Konwersja na format daty\n",
    "print(df)\n",
    "```\n",
    "\n",
    "### Wynikowa tabela wygląda tak:\n",
    "\n",
    "| order_id | customer | amount | order_date |\n",
    "|----------|----------|--------|------------|\n",
    "| 1        | Anna     | 150    | 2023-10-05 |\n",
    "| 2        | Bartek   | 240    | 2023-10-15 |\n",
    "| 3        | Celina   | 50     | 2023-11-01 |\n",
    "| 4        | Daniel   | 330    | 2023-11-05 |\n",
    "| 5        | Ewa      | 90     | 2023-11-10 |\n",
    "\n",
    "### Cel:\n",
    "Załóżmy, że chcemy filtrować zamówienia z listopada lub zamówienia o wartości powyżej 100 zł. W Pandas mamy różne sposoby filtrowania, które omówię poniżej krok po kroku.\n",
    "\n",
    "## Krok 2: Filtracja na podstawie jednej kolumny\n",
    "\n",
    "Chcemy wybrać zamówienia, których wartość (`amount`) jest większa niż 100 zł.\n",
    "\n",
    "```python\n",
    "filtered_df = df[df['amount'] > 100]\n",
    "print(filtered_df)\n",
    "```\n",
    "\n",
    "#### Wynik:\n",
    "\n",
    "| order_id | customer | amount | order_date |\n",
    "|----------|----------|--------|------------|\n",
    "| 1        | Anna     | 150    | 2023-10-05 |\n",
    "| 2        | Bartek   | 240    | 2023-10-15 |\n",
    "| 4        | Daniel   | 330    | 2023-11-05 |\n",
    "\n",
    "**Wyjaśnienie**: W Pandas zapisujemy filtrację jako warunek (`df['amount'] > 100`), który zwraca wartości `True` lub `False` dla każdej komórki kolumny `amount`. Następnie stosujemy ten warunek na całym DataFrame (`df[...]`), aby uzyskać tylko te wiersze, gdzie warunek jest `True`.\n",
    "\n",
    "---\n",
    "\n",
    "## Krok 3: Filtrowanie na podstawie kilku warunków\n",
    "\n",
    "Możemy łączyć warunki, np. znaleźć zamówienia o wartości większej niż 100 zł oraz złożone w listopadzie 2023.\n",
    "\n",
    "```python\n",
    "filtered_df = df[(df['amount'] > 100) & (df['order_date'].dt.month == 11)]\n",
    "print(filtered_df)\n",
    "```\n",
    "\n",
    "#### Wynik:\n",
    "\n",
    "| order_id | customer | amount | order_date |\n",
    "|----------|----------|--------|------------|\n",
    "| 4        | Daniel   | 330    | 2023-11-05 |\n",
    "\n",
    "**Wyjaśnienie**: Stosujemy tutaj dwa warunki jednocześnie:\n",
    "- `df['amount'] > 100` — sprawdza, czy wartość zamówienia jest większa niż 100 zł.\n",
    "- `df['order_date'].dt.month == 11` — sprawdza, czy zamówienie zostało złożone w listopadzie (korzystamy z `.dt.month`, aby uzyskać miesiąc z daty).\n",
    "\n",
    "Operatory `&` (i), `|` (lub) pozwalają łączyć warunki, ale każdy warunek powinien być ujęty w nawiasach.\n",
    "\n",
    "---\n",
    "\n",
    "## Krok 4: Filtracja na podstawie wartości tekstowych\n",
    "\n",
    "Załóżmy, że interesują nas zamówienia od klienta o imieniu `Bartek`.\n",
    "\n",
    "```python\n",
    "filtered_df = df[df['customer'] == 'Bartek']\n",
    "print(filtered_df)\n",
    "```\n",
    "\n",
    "#### Wynik:\n",
    "\n",
    "| order_id | customer | amount | order_date |\n",
    "|----------|----------|--------|------------|\n",
    "| 2        | Bartek   | 240    | 2023-10-15 |\n",
    "\n",
    "---\n",
    "\n",
    "## Krok 5: Filtracja za pomocą `isin()` - wartości z listy\n",
    "\n",
    "Jeśli chcemy zobaczyć zamówienia od klientów `Anna` lub `Daniel`, użyjemy metody `.isin()`.\n",
    "\n",
    "```python\n",
    "filtered_df = df[df['customer'].isin(['Anna', 'Daniel'])]\n",
    "print(filtered_df)\n",
    "```\n",
    "\n",
    "#### Wynik:\n",
    "\n",
    "| order_id | customer | amount | order_date |\n",
    "|----------|----------|--------|------------|\n",
    "| 1        | Anna     | 150    | 2023-10-05 |\n",
    "| 4        | Daniel   | 330    | 2023-11-05 |\n",
    "\n",
    "**Wyjaśnienie**: `isin()` przyjmuje listę wartości i zwraca wiersze, które zawierają jedną z wartości na liście.\n",
    "\n",
    "---\n",
    "\n",
    "## Ciekawostka: Filtracja na podstawie wyrażeń regularnych\n",
    "\n",
    "Pandas pozwala również na filtrowanie danych tekstowych przy użyciu wyrażeń regularnych. Na przykład, aby znaleźć klientów, których imię zaczyna się na literę \"A\", możemy skorzystać z `.str.contains()`.\n",
    "\n",
    "```python\n",
    "filtered_df = df[df['customer'].str.contains('^A')]\n",
    "print(filtered_df)\n",
    "```\n",
    "\n",
    "#### Wynik:\n",
    "\n",
    "| order_id | customer | amount | order_date |\n",
    "|----------|----------|--------|------------|\n",
    "| 1        | Anna     | 150    | 2023-10-05 |\n",
    "\n",
    "**Wyjaśnienie**: `str.contains('^A')` wyszukuje teksty zaczynające się od litery \"A\". Symbol `^` oznacza początek tekstu w wyrażeniu regularnym.\n",
    "\n",
    "---\n",
    "\n",
    "## Podsumowanie\n",
    "\n",
    "Pandas oferuje dużą elastyczność w filtrowaniu danych:\n",
    "\n",
    "- Prosta filtracja: `df[df['column'] <value>]`\n",
    "- Łączenie warunków: `&` dla \"i\", `|` dla \"lub\".\n",
    "- Wartości z listy: `.isin(['value1', 'value2'])`\n",
    "- Filtrowanie tekstowe: `.str.contains('regex')`\n",
    "\n",
    "\n",
    "### Dobre praktyki: Przeniesienie warunku filtrującego do zmiennej\n",
    "\n",
    "### Dlaczego warto przenieść warunek do zmiennej?\n",
    "\n",
    "Przeniesienie warunku do zmiennej pomaga:\n",
    "\n",
    "1. **Zwiększyć czytelność** kodu, szczególnie przy bardziej złożonych warunkach.\n",
    "2. **Uniknąć powtarzania** tych samych warunków w różnych częściach kodu.\n",
    "3. **Ułatwić modyfikacje** — jeśli musisz zmienić warunek, zmieniasz go w jednym miejscu.\n",
    "\n",
    "### Przykład zastosowania\n",
    "\n",
    "Załóżmy, że chcemy wyfiltrować zamówienia o wartości większej niż 100 zł i złożone w listopadzie. Możemy przenieść warunki do zmiennych:\n",
    "\n",
    "```python\n",
    "# Tworzymy zmienne z warunkami\n",
    "amount_condition = df['amount'] > 100\n",
    "date_condition = df['order_date'].dt.month == 11\n",
    "\n",
    "# Tworzymy maskę logiczną na podstawie zmiennych\n",
    "mask = amount_condition & date_condition\n",
    "\n",
    "# Filtrowanie DataFrame za pomocą maski\n",
    "filtered_df = df[mask]\n",
    "print(filtered_df)\n",
    "```\n",
    "\n",
    "### Wynik:\n",
    "\n",
    "| order_id | customer | amount | order_date |\n",
    "|----------|----------|--------|------------|\n",
    "| 4        | Daniel   | 330    | 2023-11-05 |\n",
    "\n",
    "### Dlaczego to rozwiązanie jest lepsze?\n",
    "\n",
    "1. **Czytelność**: Każda zmienna (`amount_condition`, `date_condition`) jasno opisuje, jaki jest cel warunku.\n",
    "2. **Łatwość modyfikacji**: Jeśli zmienią się kryteria filtrowania, np. chcemy sprawdzić zamówienia z października zamiast listopada, wystarczy zmodyfikować tylko `date_condition`.\n",
    "3. **Reużywalność**: Możemy łatwo stosować te same warunki w innych miejscach kodu.\n",
    "\n",
    "---\n",
    "\n",
    "## Podsumowanie: Dobre praktyki z maskami logicznymi i zmiennymi warunków\n",
    "\n",
    "- **Twórz maski logiczne** dla każdego warunku osobno, aby kod był bardziej przejrzysty.\n",
    "- **Przenoś warunki do zmiennych** i nadawaj im jasne nazwy, aby kod był bardziej zrozumiały i łatwiejszy do modyfikacji.\n",
    "- **Unikaj powtarzania kodu** — raz zdefiniowane warunki mogą być stosowane w różnych miejscach kodu.\n",
    "\n",
    "\n",
    "Pandas oferuje metody `where` i `query`, które są bardzo przydatne przy filtrowaniu danych. Każda z nich ma inne zastosowania i może być przydatna w różnych sytuacjach. Zobaczmy krok po kroku, jak działają obie te metody oraz jak i kiedy je stosować.\n",
    "\n",
    "### Metoda `where`\n",
    "\n",
    "- Jak działa `where`?\n",
    "\n",
    "Metoda `where` w Pandas działa trochę jak maska logiczna — zachowuje tylko te wiersze, które spełniają warunek, a pozostałe zamienia na wartości `NaN` (czyli brak danych). Nie usuwa wierszy, które nie spełniają warunku, tylko zastępuje je pustymi wartościami, co jest przydatne, gdy chcesz zachować oryginalny układ danych.\n",
    "\n",
    "### Przykład zastosowania `where`\n",
    "\n",
    "Załóżmy, że mamy DataFrame z danymi o zamówieniach:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'order_id': [1, 2, 3, 4, 5],\n",
    "    'customer': ['Anna', 'Bartek', 'Celina', 'Daniel', 'Ewa'],\n",
    "    'amount': [150, 240, 50, 330, 90],\n",
    "    'order_date': ['2023-10-05', '2023-10-15', '2023-11-01', '2023-11-05', '2023-11-10']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df['order_date'] = pd.to_datetime(df['order_date'])\n",
    "```\n",
    "\n",
    "Jeśli chcemy zachować tylko te zamówienia, których wartość (`amount`) jest większa niż 100, ale nie usuwać pozostałych wierszy, możemy użyć `where`:\n",
    "\n",
    "```python\n",
    "filtered_df = df.where(df['amount'] > 100)\n",
    "print(filtered_df)\n",
    "```\n",
    "\n",
    "#### Wynik:\n",
    "\n",
    "| order_id | customer | amount | order_date |\n",
    "|----------|----------|--------|------------|\n",
    "| 1        | Anna     | 150    | 2023-10-05 |\n",
    "| 2        | Bartek   | 240    | 2023-10-15 |\n",
    "| NaN      | NaN      | NaN    | NaT        |\n",
    "| 4        | Daniel   | 330    | 2023-11-05 |\n",
    "| NaN      | NaN      | NaN    | NaT        |\n",
    "\n",
    "**Co się stało?** Wiersze, które nie spełniają warunku (`amount > 100`), zostały zastąpione przez `NaN`.\n",
    "\n",
    "#### Zastosowania `where`\n",
    "\n",
    "- **Filtrowanie z zachowaniem układu danych**: Idealne, gdy chcesz „oznaczyć” pewne wartości bez usuwania wierszy, co jest przydatne przy analizach porównawczych lub gdy chcesz zwizualizować różnice.\n",
    "- **Przydaje się do maskowania danych**: Na przykład, gdy chcesz zastąpić pewne wartości, ale zachować ogólny kontekst.\n",
    "\n",
    "---\n",
    "\n",
    "## Metoda `query`\n",
    "\n",
    "### Jak działa `query`?\n",
    "\n",
    "Metoda `query` pozwala filtrować dane za pomocą zapytań napisanych jako wyrażenia tekstowe, podobnie jak w SQL. Jest to przydatne, gdy chcesz filtrować dane w bardziej złożony sposób, korzystając z bardziej naturalnego, tekstowego formatu.\n",
    "\n",
    "Metoda `query` jest szczególnie przydatna, gdy:\n",
    "1. Chcesz używać nazw kolumn, które są długie lub mają spacje.\n",
    "2. Masz złożone filtry i chcesz zapisać je w bardziej zwięzły sposób.\n",
    "\n",
    "### Przykład zastosowania `query`\n",
    "\n",
    "Załóżmy, że chcemy znaleźć zamówienia o wartości powyżej 100 zł, które zostały złożone w listopadzie.\n",
    "\n",
    "```python\n",
    "filtered_df = df.query('amount > 100 and order_date.dt.month == 11')\n",
    "print(filtered_df)\n",
    "```\n",
    "\n",
    "#### Wynik:\n",
    "\n",
    "| order_id | customer | amount | order_date |\n",
    "|----------|----------|--------|------------|\n",
    "| 4        | Daniel   | 330    | 2023-11-05 |\n",
    "\n",
    "### Jak działa zapytanie?\n",
    "\n",
    "W `query` zapisujemy warunki jako tekst, więc `amount > 100 and order_date.dt.month == 11` oznacza „znajdź wszystkie zamówienia, których wartość przekracza 100 zł i zostały złożone w listopadzie”.\n",
    "\n",
    "### Zastosowania `query`\n",
    "\n",
    "- **Zwięzły zapis warunków**: `query` pozwala uniknąć używania dodatkowych nawiasów i operatorów `&`, `|`, co może poprawić czytelność kodu.\n",
    "- **Kiedy kolumny mają spacje lub nietypowe znaki**: `query` umożliwia dostęp do kolumn przez zapis `[\"nazwa kolumny\"]` bezpośrednio w wyrażeniu.\n",
    "- **Do bardziej skomplikowanych zapytań**: Gdy chcesz połączyć wiele warunków, `query` pozwala zachować czytelność.\n",
    "\n",
    "---\n",
    "\n",
    "## Porównanie: `where` vs `query`\n",
    "\n",
    "| Aspekt            | `where`                                    | `query`                                     |\n",
    "|-------------------|--------------------------------------------|---------------------------------------------|\n",
    "| **Działanie**     | Zastępuje wartości niespełniające warunku na `NaN` | Usuwa wiersze, które nie spełniają warunku  |\n",
    "| **Zastosowanie**  | Maskowanie danych bez ich usuwania         | Tworzenie bardziej czytelnych, złożonych filtrów |\n",
    "| **Przykłady**     | Przy analizach porównawczych               | Gdy kolumny mają spacje lub chcemy złożone zapytania |\n",
    "| **Złożoność**     | Lepsze do prostych operacji                | Lepsze do złożonych wyrażeń                  |\n",
    "\n",
    "---\n",
    "\n",
    "## Przykład łączonego zastosowania\n",
    "\n",
    "Możemy także użyć obu metod razem, np. tworząc maskę z `where` i później stosując `query`.\n",
    "\n",
    "```python\n",
    "# Tworzenie maski za pomocą where\n",
    "masked_df = df.where(df['amount'] > 50)\n",
    "\n",
    "# Stosowanie query na wynikowym DataFrame\n",
    "result_df = masked_df.query('order_date.dt.month == 11')\n",
    "print(result_df)\n",
    "```\n",
    "\n",
    "To podejście może być przydatne, jeśli chcemy najpierw ograniczyć zbiór danych (np. `where`) i potem stosować bardziej złożone filtrowanie (`query`).\n",
    "\n",
    "---\n",
    "\n",
    "## Podsumowanie\n",
    "\n",
    "- **`where`**: Przydaje się, gdy chcesz zachować strukturalny układ danych i tylko „zaznaczyć” wartości, które nie spełniają warunków.\n",
    "- **`query`**: Najlepiej używać przy bardziej złożonych filtrach i zapytaniach, zwłaszcza gdy chcesz, by kod był bardziej czytelny i zwięzły.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrowanie grup danych\n",
    "\n",
    "Pandas oferuje kilka użytecznych metod do filtrowania danych: `isin`, `isnull`, `notnull` i `between`. Każda z nich pozwala na szybkie znalezienie wierszy na podstawie określonych kryteriów. Omówmy je krótko.\n",
    "\n",
    "## 1. `isin`\n",
    "\n",
    "Metoda `isin` pozwala sprawdzić, czy wartości w kolumnie należą do określonego zbioru wartości. Jest przydatna, gdy chcemy filtrować dane na podstawie wielu możliwych wartości.\n",
    "\n",
    "### Przykład\n",
    "\n",
    "Załóżmy, że mamy DataFrame z danymi o osobach:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = {'name': ['Anna', 'Bartek', 'Celina', 'Daniel', 'Ewa'],\n",
    "        'age': [28, 34, 19, 40, 22]}\n",
    "df = pd.DataFrame(data)\n",
    "```\n",
    "\n",
    "Chcemy wybrać osoby o imionach „Anna” lub „Ewa”:\n",
    "\n",
    "```python\n",
    "filtered_df = df[df['name'].isin(['Anna', 'Ewa'])]\n",
    "print(filtered_df)\n",
    "```\n",
    "\n",
    "**Wynik:**\n",
    "\n",
    "| name  | age |\n",
    "|-------|-----|\n",
    "| Anna  | 28  |\n",
    "| Ewa   | 22  |\n",
    "\n",
    "### Zastosowanie\n",
    "\n",
    "`isin` jest szczególnie przydatne przy pracy z danymi kategorycznymi, gdzie chcemy filtrować na podstawie listy wartości.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. `isnull`\n",
    "\n",
    "Metoda `isnull` sprawdza, które wartości w DataFrame są puste (`NaN`). Zwraca wartość `True` dla `NaN` i `False` dla pozostałych wartości. Przydaje się, gdy chcemy znaleźć i przeanalizować brakujące dane.\n",
    "\n",
    "### Przykład\n",
    "\n",
    "Załóżmy, że mamy DataFrame z brakującymi danymi:\n",
    "\n",
    "```python\n",
    "data = {'name': ['Anna', 'Bartek', 'Celina', None, 'Ewa'],\n",
    "        'age': [28, 34, None, 40, 22]}\n",
    "df = pd.DataFrame(data)\n",
    "```\n",
    "\n",
    "Chcemy znaleźć wiersze z brakującymi wartościami w kolumnie `name`:\n",
    "\n",
    "```python\n",
    "null_df = df[df['name'].isnull()]\n",
    "print(null_df)\n",
    "```\n",
    "\n",
    "**Wynik:**\n",
    "\n",
    "| name | age |\n",
    "|------|-----|\n",
    "| None | 40  |\n",
    "\n",
    "### Zastosowanie\n",
    "\n",
    "Używamy `isnull`, aby identyfikować brakujące dane i potencjalnie uzupełniać je lub usuwać.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. `notnull`\n",
    "\n",
    "Metoda `notnull` jest przeciwieństwem `isnull`. Zwraca `True` dla wartości niepustych i `False` dla `NaN`. Przydaje się, gdy chcemy pracować tylko z wierszami, które mają kompletne dane.\n",
    "\n",
    "### Przykład\n",
    "\n",
    "Chcemy znaleźć wiersze, gdzie kolumna `age` nie jest pusta:\n",
    "\n",
    "```python\n",
    "notnull_df = df[df['age'].notnull()]\n",
    "print(notnull_df)\n",
    "```\n",
    "\n",
    "**Wynik:**\n",
    "\n",
    "| name   | age |\n",
    "|--------|-----|\n",
    "| Anna   | 28  |\n",
    "| Bartek | 34  |\n",
    "| Daniel | 40  |\n",
    "| Ewa    | 22  |\n",
    "\n",
    "### Zastosowanie\n",
    "\n",
    "`notnull` jest użyteczne, gdy chcemy wyeliminować brakujące dane z dalszych analiz.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. `between`\n",
    "\n",
    "Metoda `between` pozwala filtrować dane na podstawie przedziału wartości (zakresu). Działa tylko na dane numeryczne i daty.\n",
    "\n",
    "### Przykład\n",
    "\n",
    "Załóżmy, że chcemy znaleźć osoby w wieku między 20 a 30 lat:\n",
    "\n",
    "```python\n",
    "age_filtered_df = df[df['age'].between(20, 30)]\n",
    "print(age_filtered_df)\n",
    "```\n",
    "\n",
    "**Wynik:**\n",
    "\n",
    "| name  | age |\n",
    "|-------|-----|\n",
    "| Anna  | 28  |\n",
    "| Ewa   | 22  |\n",
    "\n",
    "### Zastosowanie\n",
    "\n",
    "`between` jest wygodne, gdy chcemy ustawić dolną i górną granicę filtrowania, np. dla wieku, cen czy dat.\n",
    "\n",
    "---\n",
    "\n",
    "## Podsumowanie\n",
    "\n",
    "- **`isin`** – filtrowanie na podstawie listy wartości.\n",
    "- **`isnull`** – identyfikacja brakujących danych.\n",
    "- **`notnull`** – wybór tylko niepustych wartości.\n",
    "- **`between`** – filtrowanie w zakresie (dolna i górna granica).\n",
    "\n",
    "Każda z tych metod ma swoje specyficzne zastosowania, ale wszystkie ułatwiają szybkie filtrowanie i czyszczenie danych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## duplikaty i wartości unikalne\n",
    "\n",
    "### Metoda `is_unique`\n",
    "\n",
    "Metoda `is_unique` jest atrybutem, zwraca wartość logiczną (`True` lub `False`) dla serii danych, oznaczającą, czy wszystkie wartości w tej serii są unikalne.\n",
    "\n",
    "**Przykład:**\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = {'Imię': ['Alice', 'Bob', 'Charlie', 'Alice']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df['Imię'].is_unique)  # Output: False, ponieważ \"Alice\" powtarza się\n",
    "```\n",
    "\n",
    "### Metoda `unique()`\n",
    "\n",
    "Metoda `unique()` zwraca tablicę unikalnych wartości w serii danych.\n",
    "\n",
    "**Przykład:**\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = {'Imię': ['Alice', 'Bob', 'Charlie', 'Alice']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df['Imię'].unique())  # Output: ['Alice' 'Bob' 'Charlie']\n",
    "```\n",
    "\n",
    "### Metoda `nunique()`\n",
    "\n",
    "Metoda `nunique()` zwraca liczbę unikalnych wartości w serii danych.\n",
    "\n",
    "**Przykład:**\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = {'Imię': ['Alice', 'Bob', 'Charlie', 'Alice']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df['Imię'].nunique())  # Output: 3, ponieważ są trzy unikalne imiona\n",
    "```\n",
    "\n",
    "### Metoda `duplicated()`\n",
    "\n",
    "Metoda `duplicated()` zwraca serię wartości logicznych (`True` lub `False`) dla każdego wiersza DataFrame'a, oznaczającą, czy ten wiersz jest duplikatem poprzednich.\n",
    "\n",
    "**Przykład:**\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = {'Imię': ['Alice', 'Bob', 'Charlie', 'Alice']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df.duplicated())  # Output: \n",
    "# 0    False\n",
    "# 1    False\n",
    "# 2    False\n",
    "# 3     True\n",
    "```\n",
    "\n",
    "### Metoda `drop_duplicates()`\n",
    "\n",
    "Metoda `drop_duplicates()` usuwa z DataFrame'a duplikaty wierszy. Możesz określić, które kolumny powinny być brane pod uwagę przy wykrywaniu duplikatów.\n",
    "\n",
    "**Przykład:**\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = {'Imię': ['Alice', 'Bob', 'Charlie', 'Alice'],\n",
    "        'Wiek': [25, 30, 35, 25]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Usuwanie duplikatów z uwzględnieniem wszystkich kolumn\n",
    "df_bez_duplikatów = df.drop_duplicates()\n",
    "print(df_bez_duplikatów)\n",
    "# Output:\n",
    "#      Imię  Wiek\n",
    "# 0   Alice    25\n",
    "# 1     Bob    30\n",
    "# 2 Charlie    35\n",
    "\n",
    "# Usuwanie duplikatów tylko w kolumnie 'Imię'\n",
    "df_bez_duplikatów_imiona = df.drop_duplicates(subset='Imię')\n",
    "print(df_bez_duplikatów_imiona)\n",
    "# Output:\n",
    "#      Imię  Wiek\n",
    "# 0   Alice    25\n",
    "# 1     Bob    30\n",
    "# 2 Charlie    35\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modyfikacja danych\n",
    "\n",
    "### Zmiana nazwy kolumny\n",
    "\n",
    "1. Funkcja rename() - Ta funkcja pozwala na zmianę nazwy jednej lub wielu kolumn w dataframe'ie. Przykładowo, aby zmienić nazwę kolumny \"A\" na \"Nowy_nazwa\", można użyć następującego kodu:\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "print(df)\n",
    "# Oryginalny dataframe\n",
    "\n",
    "df = df.rename(columns={'A': 'Nowy_nazwa'})\n",
    "print(df)\n",
    "# Dataframe z zmienioną nazwą kolumny \"A\" na \"Nowy_nazwa\"\n",
    "```\n",
    "2. Przypisanie nowej nazwy kolumnie - Można też zmieniać nazwy kolumn bezpośrednio w dataframe'ie za pomocą operatora przypisania (=). Przykładowo, aby zmienić nazwę kolumny \"A\" na \"Nowy_nazwa\", można użyć następującego kodu:\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "print(df)\n",
    "# Oryginalny dataframe\n",
    "\n",
    "df['Nowy_nazwa'] = df['A']\n",
    "del df['A']\n",
    "print(df)\n",
    "# Dataframe z zmienioną nazwą kolumny \"A\" na \"Nowy_nazwa\"\n",
    "```\n",
    "3. Modyfikacja indexu - W przypadku dataframe'a, w którym index to pierwszy rząd i jest on widoczny (np. `df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})`), można też zmienić nazwę kolumny poprzez modyfikację indexu. Przykładowo, aby zmienić nazwę kolumny \"A\" na \"Nowy_nazwa\", można użyć następującego kodu:\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "print(df)\n",
    "# Oryginalny dataframe\n",
    "\n",
    "df.columns = df.columns.str.replace('A', 'Nowy_nazwa')\n",
    "print(df)\n",
    "# Dataframe z zmienioną nazwą kolumny \"A\" na \"Nowy_nazwa\"\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
